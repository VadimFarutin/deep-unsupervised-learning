{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "HSE_DUL_HW02_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VadimFarutin/deep-unsupervised-learning/blob/hw02/hw02_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJqNPVBJroKY",
        "colab_type": "text"
      },
      "source": [
        "# HW02"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SrQu_IAartq0",
        "colab_type": "text"
      },
      "source": [
        "## 2 High-dimensional data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okcxjqsMkjkB",
        "colab_type": "text"
      },
      "source": [
        "### Imports and Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfYk_JjWsim4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!pip install graphql-core==2.0\n",
        "!pip install wandb -q"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mx6pvu3gspLN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import wandb\n",
        "!wandb login"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GdLTPv3xdKi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import defaultdict\n",
        "from tqdm import tnrange, tqdm_notebook\n",
        "from tqdm.auto import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import random\n",
        "import pickle\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.modules import loss\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data.dataset import Dataset\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.distributions import Normal, Uniform, MultivariateNormal"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnFSXUV3xdK0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SEED = 42\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "th_KCfdCxdLC",
        "colab_type": "code",
        "outputId": "69f8e5ec-59d5-45ae-a547-47f640e93495",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# DEVICE = torch.device('cpu')\n",
        "print(DEVICE)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQAiBChL3h3q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "fbb2808c-0a82-4ebe-d00a-189233f154a6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZvr0NM23p8S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_data():\n",
        "    path = 'drive/My Drive/hw2_q2.pkl'\n",
        "\n",
        "    with open(path, 'rb') as file:\n",
        "        dataset = pickle.load(file)\n",
        "    \n",
        "    return dataset['train'].transpose(0, 3, 1, 2), dataset['test'].transpose(0, 3, 1, 2)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1Ni4f8NxdLt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train, val = read_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuWkev9L00yv",
        "colab_type": "code",
        "outputId": "77db3879-b122-45ee-d1d6-85c98d471cb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(train.shape, val.shape)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20000, 3, 32, 32) (6838, 3, 32, 32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HhGDJi7xvWt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def MyNLLLoss(y):\n",
        "    return -torch.mean(torch.log(y)) / 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xw73WgmxdNT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit(model, train, val, optimizer, loss_function, epoch_cnt, batch_size):\n",
        "    train_loader = torch.utils.data.DataLoader(torch.from_numpy(train), batch_size=batch_size, shuffle=True)\n",
        "    val_loader = torch.utils.data.DataLoader(torch.from_numpy(val), batch_size=batch_size)\n",
        "    train_loss_values = []\n",
        "    val_loss_values = []\n",
        "            \n",
        "    for epoch in tnrange(epoch_cnt, desc='Epoch'):\n",
        "        model.train()\n",
        "        for batch_data in train_loader:\n",
        "            x = batch_data.float().to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(x)\n",
        "            loss = loss_function(output)\n",
        "            train_loss_values.append(loss)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            wandb.log({\"Train Loss\": loss})\n",
        "\n",
        "        loss_values = []\n",
        "        model.eval()\n",
        "        for batch_data in val_loader:\n",
        "            x = batch_data.float().to(DEVICE)\n",
        "            output = model(x)\n",
        "            loss = loss_function(output)\n",
        "            loss_values.append(loss.item())\n",
        "        val_loss_values.append(np.mean(np.array(loss_values)))\n",
        "\n",
        "        wandb.log({\"Validation Loss\": val_loss_values[-1]})\n",
        "    \n",
        "    return train_loss_values, val_loss_values \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsH8OQi0xdNy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_loss_values(train_loss_values, val_loss_values):\n",
        "    plt.plot(np.arange(len(train_loss_values)), train_loss_values, color='blue', label='train')\n",
        "    plt.plot(np.arange(0, len(train_loss_values), len(train_loss_values) / config.epochs), val_loss_values, color='red', label='validation')\n",
        "    plt.legend()\n",
        "    plt.title(\"Loss values\")\n",
        "    plt.xlabel(\"iteration\")\n",
        "    plt.ylabel(\"loss\")\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUW2EIlZY_6y",
        "colab_type": "text"
      },
      "source": [
        "### RealNVP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hH8pCSaP_6Yu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, channels, type):\n",
        "        super(ResBlock, self).__init__()\n",
        "\n",
        "        if type == 'A':\n",
        "            self.layers = nn.Sequential(nn.Conv2d(channels, channels, kernel_size=(1, 1), stride=(1, 1), padding=0),\n",
        "                                        nn.ReLU(),\n",
        "                                        nn.Conv2d(channels, channels, kernel_size=(3, 3), stride=(1, 1), padding=1))        \n",
        "        else:\n",
        "            self.layers = nn.Sequential(nn.ReLU(),\n",
        "                                        nn.Conv2d(channels, channels, kernel_size=(1,1), stride=(1, 1), padding=0))\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.layers(x)\n",
        "        return out\n",
        "\n",
        "    def __call__(self, x):\n",
        "        return self.forward(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_UHFBMcCeoD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Resnet(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_size, n_blocks):\n",
        "        super(Resnet, self).__init__()\n",
        "        out_channels = in_channels * 2\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels, hidden_size, kernel_size=(3, 3), stride=(1, 1), padding=2)\n",
        "\n",
        "        self.res_blocks_a = torch.nn.ModuleList([ResBlock(hidden_size, 'A')\n",
        "                                                 for _ in range(n_blocks)])\n",
        "        self.res_blocks_b = torch.nn.ModuleList([ResBlock(hidden_size, 'B')\n",
        "                                                 for _ in range(n_blocks)])\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "        self.conv2 = nn.Conv2d(hidden_size, out_channels, kernel_size=(3, 3), stride=(1, 1))\n",
        "    \n",
        "    def forward(self, x):\n",
        "        h = self.conv1(x)\n",
        "\n",
        "        for res_block_a, res_block_b in zip(self.res_blocks_a, self.res_blocks_b):\n",
        "            _h = self.res_block_a(h)\n",
        "            h = self.res_block_b(_h)\n",
        "            h = h + _h\n",
        "\n",
        "        h = self.relu(h)\n",
        "        x = self.conv2(h)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def __call__(self, x):\n",
        "        return self.forward(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYBWaChM7gWq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AffineCoupling(nn.Module):\n",
        "    def __init__(self, mask, in_channels):\n",
        "        super(AffineCoupling, self).__init__()\n",
        "        self.mask = mask\n",
        "        self.resnet = Resnet(in_channels, hidden_size=256, n_blocks=8)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        y1 = self.mask * x\n",
        "        log_s, t = torch.chunk(self.resnet(y1), 2, dim=1)\n",
        "        log_det = log_s.view(y1.shape[0], -1).sum(dim=1)\n",
        "\n",
        "        return log_det\n",
        "\n",
        "    def latent(self, x):\n",
        "        y1 = self.mask * x\n",
        "        log_s, t = torch.chunk(self.resnet(y1), 2, dim=1)\n",
        "        y2 = (1 - self.mask) * torch.exp(log_s) * (x2 + t)\n",
        "\n",
        "        return y1 + y2\n",
        "\n",
        "    def inverse(self, y):\n",
        "        x1 = self.mask * y\n",
        "        log_s, t = torch.chunk(self.resnet(x1), 2, dim=1)\n",
        "        x2 = (1 - self.mask) * y * torch.exp(-log_s) - t\n",
        "\n",
        "        return x1 + x2\n",
        "        \n",
        "    def __call__(self, x):\n",
        "        return self.forward(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COE5HU5bDb6h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyRealNVP(nn.Module):\n",
        "    def __init__(self, in_channels, size):\n",
        "        super(MyRealNVP, self).__init__()\n",
        "\n",
        "        mask = self.checkerboard_mask(in_channels, size)\n",
        "        self.couplings1 = nn.Sequential(AffineCoupling(mask, in_channels),\n",
        "                                        AffineCoupling(1 - mask, in_channels),\n",
        "                                        AffineCoupling(mask, in_channels),\n",
        "                                        AffineCoupling(1 - mask, in_channels))\n",
        "\n",
        "        size = size[0] // 2, size[1] // 2\n",
        "        mask = self.channel_split_mask(in_channels, size)\n",
        "        self.couplings1 = nn.Sequential(AffineCoupling(mask, in_channels * 4),\n",
        "                                        AffineCoupling(1 - mask, in_channels),\n",
        "                                        AffineCoupling(mask, in_channels * 4))\n",
        "\n",
        "        mask = self.checkerboard_mask(in_channels, size)\n",
        "        self.couplings1 = nn.Sequential(AffineCoupling(mask, in_channels * 4),\n",
        "                                        AffineCoupling(1 - mask, in_channels),\n",
        "                                        AffineCoupling(mask, in_channels * 4))\n",
        "\n",
        "        size = size[0] // 2, size[1] // 2\n",
        "        mask = self.channel_split_mask(in_channels, size)\n",
        "        self.couplings1 = nn.Sequential(AffineCoupling(mask, in_channels * 16),\n",
        "                                        AffineCoupling(1 - mask, in_channels),\n",
        "                                        AffineCoupling(mask, in_channels * 16))\n",
        "\n",
        "        mask = self.checkerboard_mask(in_channels, size)\n",
        "        self.couplings1 = nn.Sequential(AffineCoupling(mask, in_channels * 16),\n",
        "                                        AffineCoupling(1 - mask, in_channels),\n",
        "                                        AffineCoupling(mask, in_channels * 16))\n",
        "\n",
        "    def checkerboard_mask(self, in_channels, size):\n",
        "        black = np.ones([1, in_channels, size[0], size[1]], dtype=np.bool)\n",
        "        white = np.ones([1, in_channels, size[0], size[1]], dtype=np.bool)\n",
        "        black[:, :, np.arange(1, size[0], 2), :] = False \n",
        "        white[:, :, :, np.arange(0, size[1], 2)] = False\n",
        "        mask = torch.tensor(black ^ white, dtype=torch.float32).to(DEVICE)\n",
        "\n",
        "        return mask\n",
        "\n",
        "    def channel_split_mask(self, in_channels, size):\n",
        "        mask = torch.zeros([1, in_channels, size[0], size[1]], dtype=torch.float32).to(DEVICE)\n",
        "        channels_i = np.arange(0, in_channels // 4) * 4\n",
        "        channels_i = np.stack((channels_i, channels_i + 1), axis=1).reshape(-1)\n",
        "        mask[:, channels_i, :, :] = 1.0\n",
        "\n",
        "        return mask\n",
        "    \n",
        "    def squeeze(self, x):\n",
        "        b, c, h, w = x.shape\n",
        "        return F.unfold(x, (2, 2), stride=2).reshape(b, 4 * c, h // 2, w // 2)\n",
        "\n",
        "    def unsqueeze(self, x):\n",
        "        b, c, h, w = x.shape\n",
        "        return F.fold(x.reshape(b, c, -1), (h * 2, w * 2), (2, 2), stride=2)\n",
        "            \n",
        "    def forward(self, x):\n",
        "        logdet = torch.zeros((x.shape[0], 1)).to(DEVICE)\n",
        "        y = x\n",
        "       \n",
        "        for layer in self.couplings1:\n",
        "            logdet += layer(y)\n",
        "            y = layer.latent(y)\n",
        "\n",
        "        y = self.squeeze(y)\n",
        "        \n",
        "        for layer in self.couplings2:\n",
        "            logdet += layer(y)\n",
        "            y = layer.latent(y)\n",
        "        for layer in self.couplings3:\n",
        "            logdet += layer(y)\n",
        "            y = layer.latent(y)\n",
        "\n",
        "        y = self.squeeze(y)\n",
        "        \n",
        "        for layer in self.couplings4:\n",
        "            logdet += layer(y)\n",
        "            y = layer.latent(y)\n",
        "        for layer in self.couplings5:\n",
        "            logdet += layer(y)\n",
        "            y = layer.latent(y)\n",
        "        \n",
        "        logdet = torch.exp(logdet)\n",
        "\n",
        "        return logdet\n",
        "        \n",
        "    def latent(self, x):\n",
        "        y = x\n",
        "        \n",
        "        for layer in self.couplings1:\n",
        "            y = layer.latent(y)\n",
        "\n",
        "        y = self.squeeze(y)\n",
        "        \n",
        "        for layer in self.couplings2:\n",
        "            y = layer.latent(y)\n",
        "        for layer in self.couplings3:\n",
        "            y = layer.latent(y)\n",
        "\n",
        "        y = self.squeeze(y)\n",
        "        \n",
        "        for layer in self.couplings4:\n",
        "            y = layer.latent(y)\n",
        "        for layer in self.couplings5:\n",
        "            y = layer.latent(y)\n",
        "\n",
        "        y = self.unsqueeze(y)\n",
        "        y = self.unsqueeze(y)\n",
        "        \n",
        "        return y\n",
        "\n",
        "    def inverse(self, y):\n",
        "        x = y\n",
        "        x = self.squeeze(x)\n",
        "        x = self.squeeze(x)\n",
        "        \n",
        "        for layer in reversed(self.couplings5):\n",
        "            x = layer.inverse(x)\n",
        "        for layer in reversed(self.couplings4):\n",
        "            x = layer.inverse(x)\n",
        "            \n",
        "        x = self.unsqueeze(x)\n",
        "        \n",
        "        for layer in reversed(self.couplings3):\n",
        "            x = layer.inverse(x)\n",
        "        for layer in reversed(self.couplings2):\n",
        "            x = layer.inverse(x)\n",
        "            \n",
        "        x = self.unsqueeze(x)\n",
        "        \n",
        "        for layer in reversed(self.couplings1):\n",
        "            x = layer.inverse(x)\n",
        "            \n",
        "        return x\n",
        "\n",
        "    def __call__(self, x):\n",
        "        return self.forward(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "2ffb19e0-5774-4201-d4bd-7793ef70a13c",
        "id": "qBd-rgr7d1QI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "wandb.init(entity=\"vadim-farutin\", project=\"HSE-DUL-HW02-2\")\n",
        "wandb.watch_called = False # Re-run the model without restarting the runtime, unnecessary after our next release\n",
        "\n",
        "config = wandb.config\n",
        "config.lr = 1e-4\n",
        "config.batch_size = 32\n",
        "config.epochs = 2"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/vadim-farutin/HSE-DUL-HW02-2\" target=\"_blank\">https://app.wandb.ai/vadim-farutin/HSE-DUL-HW02-2</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/vadim-farutin/HSE-DUL-HW02-2/runs/7gt50b44\" target=\"_blank\">https://app.wandb.ai/vadim-farutin/HSE-DUL-HW02-2/runs/7gt50b44</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CLCpjrw0d1RC",
        "colab": {}
      },
      "source": [
        "channels = 3\n",
        "size = (32, 32)\n",
        "model = MyRealNVP(channels, size)\n",
        "model = model.float()\n",
        "model = model.to(DEVICE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IJknelYMd1RS",
        "colab": {}
      },
      "source": [
        "loss_function = MyNLLLoss\n",
        "optimizer = optim.Adam(model.parameters(), lr=config.lr, weight_decay=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Y3s-B0i4d1Rb",
        "colab": {}
      },
      "source": [
        "train_loss_values, val_loss_values =\\\n",
        "    fit(model, train, val, optimizer, loss_function, config.epochs, config.batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab_type": "code",
        "id": "PyIau5eBjCa3",
        "colab": {}
      },
      "source": [
        "plot_loss_values(train_loss_values, val_loss_values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "B3scvEa1jCbW",
        "colab": {}
      },
      "source": [
        "# z = MultivariateNormal(torch.zeros(2), torch.eye(2)).sample((10000, 2))\n",
        "# low = torch.tensor([0.0, 0.0]).to(DEVICE)\n",
        "# high = torch.tensor([1.0, 1.0]).to(DEVICE)\n",
        "# z = Uniform(low, high).rsample((10000, 2))\n",
        "\n",
        "# x1, x2 = model.inverse(z)\n",
        "# x1 = x1.cpu().detach().numpy()\n",
        "# x2 = x2.cpu().detach().numpy()\n",
        "# plt.figure()\n",
        "# plt.scatter(x1, x2)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}