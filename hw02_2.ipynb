{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "HSE_DUL_HW02_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VadimFarutin/deep-unsupervised-learning/blob/hw02/hw02_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJqNPVBJroKY",
        "colab_type": "text"
      },
      "source": [
        "# HW02"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SrQu_IAartq0",
        "colab_type": "text"
      },
      "source": [
        "## 2 High-dimensional data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okcxjqsMkjkB",
        "colab_type": "text"
      },
      "source": [
        "### Imports and Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfYk_JjWsim4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!pip install graphql-core==2.0\n",
        "!pip install wandb -q"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mx6pvu3gspLN",
        "colab_type": "code",
        "outputId": "ab8aa22e-0bd3-46b0-a2a6-5d9cded05d1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        }
      },
      "source": [
        "import wandb\n",
        "!wandb login"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Use an existing W&B account'\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://app.wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter: 8c292ca69e334e8a562d4a4c6570fdd3ad29c825\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[32mSuccessfully logged in to Weights & Biases!\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GdLTPv3xdKi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import defaultdict\n",
        "from tqdm import tnrange, tqdm_notebook\n",
        "from tqdm.auto import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import random\n",
        "import pickle\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.modules import loss\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data.dataset import Dataset\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.distributions import Normal, Uniform, MultivariateNormal"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnFSXUV3xdK0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SEED = 42\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "th_KCfdCxdLC",
        "colab_type": "code",
        "outputId": "b2d728a7-f00d-4e36-9106-86edebf6ccf9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# DEVICE = torch.device('cpu')\n",
        "print(DEVICE)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZEzd86o9yE0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPS = 1e-5\n",
        "MAX_VALUE = 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQAiBChL3h3q",
        "colab_type": "code",
        "outputId": "a3a576ca-fc7c-4387-f426-c78afd0177bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZvr0NM23p8S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_data():\n",
        "    path = 'drive/My Drive/hw2_q2.pkl'\n",
        "\n",
        "    with open(path, 'rb') as file:\n",
        "        dataset = pickle.load(file)\n",
        "    \n",
        "    return dataset['train'].transpose(0, 3, 1, 2), dataset['test'].transpose(0, 3, 1, 2)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1Ni4f8NxdLt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train, val = read_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuWkev9L00yv",
        "colab_type": "code",
        "outputId": "9657edcf-8ded-4f00-fd82-502aeeebea36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(train.shape, val.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20000, 3, 32, 32) (6838, 3, 32, 32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1cQRRvYPsFK",
        "colab_type": "text"
      },
      "source": [
        "### Common code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HhGDJi7xvWt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def MyNLLLoss(y):\n",
        "    # return -torch.mean(torch.log(y + EPS)) / 2\n",
        "    return -torch.mean(y) / 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xw73WgmxdNT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch import autograd\n",
        "\n",
        "def fit(model, train, val, optimizer, loss_function, epoch_cnt, batch_size):\n",
        "    train_loader = torch.utils.data.DataLoader(torch.from_numpy(train), batch_size=batch_size, shuffle=True)\n",
        "    val_loader = torch.utils.data.DataLoader(torch.from_numpy(val), batch_size=batch_size)\n",
        "    train_loss_values = []\n",
        "    val_loss_values = []\n",
        "            \n",
        "    with autograd.detect_anomaly():\n",
        "        for epoch in tnrange(epoch_cnt, desc='Epoch'):\n",
        "            model.train()\n",
        "            for batch_data in train_loader:\n",
        "                x = batch_data.float().to(DEVICE)\n",
        "                optimizer.zero_grad()\n",
        "                output = model(x)\n",
        "                # print(\"..............................passed forward..........................\")\n",
        "                loss = loss_function(output)\n",
        "                train_loss_values.append(loss.item())\n",
        "                loss.backward()\n",
        "                nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
        "                optimizer.step()\n",
        "                # print(\"..............................passed step..........................\")\n",
        "\n",
        "                wandb.log({\"Train Loss\": loss.item()})\n",
        "\n",
        "            loss_values = []\n",
        "            model.eval()\n",
        "            for batch_data in val_loader:\n",
        "                x = batch_data.float().to(DEVICE)\n",
        "                output = model(x)\n",
        "                loss = loss_function(output)\n",
        "                loss_values.append(loss.item())\n",
        "            val_loss_values.append(np.mean(np.array(loss_values)))\n",
        "\n",
        "            wandb.log({\"Validation Loss\": val_loss_values[-1]})\n",
        "    \n",
        "    return train_loss_values, val_loss_values \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsH8OQi0xdNy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_loss_values(train_loss_values, val_loss_values):\n",
        "    plt.plot(np.arange(len(train_loss_values)), train_loss_values, color='blue', label='train')\n",
        "    plt.plot(np.arange(0, len(train_loss_values), len(train_loss_values) / config.epochs), val_loss_values, color='red', label='validation')\n",
        "    plt.legend()\n",
        "    plt.title(\"Loss values\")\n",
        "    plt.xlabel(\"iteration\")\n",
        "    plt.ylabel(\"loss\")\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUW2EIlZY_6y",
        "colab_type": "text"
      },
      "source": [
        "### RealNVP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hH8pCSaP_6Yu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, channels, type):\n",
        "        super(ResBlock, self).__init__()\n",
        "\n",
        "        if type == 'A':\n",
        "            self.layers = nn.Sequential(nn.Conv2d(channels, channels, kernel_size=(1, 1), stride=(1, 1), padding=0),\n",
        "                                        nn.BatchNorm2d(channels),\n",
        "                                        nn.ReLU(),\n",
        "                                        nn.Conv2d(channels, channels, kernel_size=(3, 3), stride=(1, 1), padding=1),\n",
        "                                        nn.BatchNorm2d(channels))        \n",
        "        else:\n",
        "            self.layers = nn.Sequential(nn.ReLU(),\n",
        "                                        nn.Conv2d(channels, channels, kernel_size=(1,1), stride=(1, 1), padding=0))\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.layers(x)\n",
        "        return out\n",
        "\n",
        "    def __call__(self, x):\n",
        "        return self.forward(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_UHFBMcCeoD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Resnet(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_size, n_blocks):\n",
        "        super(Resnet, self).__init__()\n",
        "        out_channels = in_channels * 2\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels, hidden_size, kernel_size=(3, 3), stride=(1, 1), padding=2)\n",
        "\n",
        "        self.res_blocks_a = torch.nn.ModuleList([ResBlock(hidden_size, 'A')\n",
        "                                                 for _ in range(n_blocks)])\n",
        "        self.res_blocks_b = torch.nn.ModuleList([ResBlock(hidden_size, 'B')\n",
        "                                                 for _ in range(n_blocks)])\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "        self.conv2 = nn.Conv2d(hidden_size, out_channels, kernel_size=(3, 3), stride=(1, 1))\n",
        "    \n",
        "    def forward(self, x):\n",
        "        h = x\n",
        "        h = self.conv1(h)\n",
        "\n",
        "        for res_block_a, res_block_b in zip(self.res_blocks_a, self.res_blocks_b):\n",
        "            _h = res_block_a(h)\n",
        "            h = res_block_b(_h)\n",
        "            h = h + _h\n",
        "            h = self.relu(h)\n",
        "\n",
        "        h = self.conv2(h)\n",
        "\n",
        "        return h\n",
        "\n",
        "    def __call__(self, x):\n",
        "        return self.forward(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYBWaChM7gWq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AffineCoupling(nn.Module):\n",
        "    def __init__(self, mask, in_channels):\n",
        "        super(AffineCoupling, self).__init__()\n",
        "        self.mask = mask\n",
        "        # self.resnet = Resnet(in_channels, hidden_size=256, n_blocks=8)\n",
        "        self.resnet = Resnet(in_channels, hidden_size=64, n_blocks=1)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        y1 = self.mask * x\n",
        "        log_s, t = torch.chunk(self.resnet(y1), 2, dim=1)\n",
        "        log_det = torch.sum(log_s.view(y1.shape[0], -1), dim=1)\n",
        "\n",
        "        return log_det\n",
        "\n",
        "    def latent(self, x):\n",
        "        y1 = self.mask * x\n",
        "        log_s, t = torch.chunk(self.resnet(y1), 2, dim=1)\n",
        "        y2 = (1 - self.mask) * torch.exp(log_s) * (x + t)\n",
        "\n",
        "        return y1 + y2\n",
        "\n",
        "    def inverse(self, y):\n",
        "        x1 = self.mask * y\n",
        "        log_s, t = torch.chunk(self.resnet(x1), 2, dim=1)\n",
        "        x2 = (1 - self.mask) * y * torch.exp(-log_s) - t\n",
        "\n",
        "        return x1 + x2\n",
        "        \n",
        "    def __call__(self, x):\n",
        "        return self.forward(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZtUbjZBohorY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ActNorm(nn.Module):\n",
        "    def __init__(self, in_channels, size):\n",
        "        super(ActNorm, self).__init__()\n",
        "        \n",
        "        self.w = nn.Parameter(torch.ones([1, in_channels, size[0], size[1]]))\n",
        "        self.b = nn.Parameter(torch.zeros([1, in_channels, size[0], size[1]]))\n",
        "        \n",
        "    def forward(self, x):\n",
        "        logdet = torch.log(self.w.abs() + EPS).flatten(1).sum(dim=1)\n",
        "        return logdet\n",
        "        # return torch.zeros(x.shape[0]).to(DEVICE)\n",
        "\n",
        "    def latent(self, x):\n",
        "        y = x * self.w + self.b\n",
        "        return y\n",
        "        # return x\n",
        "\n",
        "    def inverse(self, y):\n",
        "        x = (y - self.b) / self.w\n",
        "        return x\n",
        "        # return y\n",
        "\n",
        "    def __call__(self, x):\n",
        "        return self.forward(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgOI9idUIb1F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Preprocess(nn.Module):\n",
        "    def __init__(self, alpha):\n",
        "        super(Preprocess, self).__init__()\n",
        "        \n",
        "        self.alpha = alpha\n",
        "        \n",
        "    def forward(self, x):\n",
        "        y = self.alpha + (1.0 - self.alpha) * x / 4.0\n",
        "        diag = (torch.ones_like(x) * (1.0 - self.alpha) / 4.0).flatten(start_dim=1)\n",
        "        logdet = torch.log(diag.abs()).sum(dim=1)\n",
        "        diag = (1.0 / y + 1.0 / (1.0 - y)).abs().flatten(start_dim=1)\n",
        "        logdet = logdet + torch.log(diag + EPS).sum(dim=1)\n",
        "        return logdet\n",
        "\n",
        "    def latent(self, x):\n",
        "        y = self.alpha + (1.0 - self.alpha) * x / 4.0\n",
        "        y = torch.log(y) - torch.log(1.0 - y)\n",
        "        return y\n",
        "\n",
        "    def inverse(self, y):\n",
        "        x = torch.exp(y)\n",
        "        x = x / (x + 1.0)\n",
        "        x = 4.0 * (x - self.alpha) / (1.0 - self.alpha)\n",
        "        return x\n",
        "\n",
        "    def __call__(self, x):\n",
        "        return self.forward(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COE5HU5bDb6h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyRealNVP(nn.Module):\n",
        "    def __init__(self, in_channels, size):\n",
        "        super(MyRealNVP, self).__init__()\n",
        "\n",
        "        self.preprocess = Preprocess(0.05)\n",
        "\n",
        "        mask = self.checkerboard_mask(in_channels, size)\n",
        "        self.couplings1 = nn.Sequential(AffineCoupling(mask, in_channels),\n",
        "                                        ActNorm(in_channels, size),\n",
        "                                        AffineCoupling(1 - mask, in_channels),\n",
        "                                        ActNorm(in_channels, size),\n",
        "                                        AffineCoupling(mask, in_channels),\n",
        "                                        ActNorm(in_channels, size),\n",
        "                                        AffineCoupling(1 - mask, in_channels),\n",
        "                                        ActNorm(in_channels, size)\n",
        "                                        )\n",
        "\n",
        "        size = size[0] // 2, size[1] // 2\n",
        "        in_channels = in_channels * 4\n",
        "        mask = self.channel_split_mask(in_channels, size)\n",
        "        self.couplings2 = nn.Sequential(AffineCoupling(mask, in_channels),\n",
        "                                        ActNorm(in_channels, size),\n",
        "                                        AffineCoupling(1 - mask, in_channels),\n",
        "                                        ActNorm(in_channels, size),\n",
        "                                        AffineCoupling(mask, in_channels),\n",
        "                                        ActNorm(in_channels, size))\n",
        "\n",
        "        mask = self.checkerboard_mask(in_channels, size)\n",
        "        self.couplings3 = nn.Sequential(AffineCoupling(mask, in_channels),\n",
        "                                        ActNorm(in_channels, size),\n",
        "                                        AffineCoupling(1 - mask, in_channels),\n",
        "                                        ActNorm(in_channels, size),\n",
        "                                        AffineCoupling(mask, in_channels),\n",
        "                                        ActNorm(in_channels, size))\n",
        "\n",
        "        size = size[0] // 2, size[1] // 2\n",
        "        in_channels = in_channels * 4\n",
        "        mask = self.channel_split_mask(in_channels, size)\n",
        "        self.couplings4 = nn.Sequential(AffineCoupling(mask, in_channels),\n",
        "                                        ActNorm(in_channels, size),\n",
        "                                        AffineCoupling(1 - mask, in_channels),\n",
        "                                        ActNorm(in_channels, size),\n",
        "                                        AffineCoupling(mask, in_channels),\n",
        "                                        ActNorm(in_channels, size))\n",
        "\n",
        "        mask = self.checkerboard_mask(in_channels, size)\n",
        "        self.couplings5 = nn.Sequential(AffineCoupling(mask, in_channels),\n",
        "                                        ActNorm(in_channels, size),\n",
        "                                        AffineCoupling(1 - mask, in_channels),\n",
        "                                        ActNorm(in_channels, size),\n",
        "                                        AffineCoupling(mask, in_channels),\n",
        "                                        ActNorm(in_channels, size))\n",
        "\n",
        "    def checkerboard_mask(self, in_channels, size):\n",
        "        black = np.ones([1, in_channels, size[0], size[1]], dtype=np.bool)\n",
        "        white = np.ones([1, in_channels, size[0], size[1]], dtype=np.bool)\n",
        "        black[:, :, np.arange(1, size[0], 2), :] = False \n",
        "        white[:, :, :, np.arange(0, size[1], 2)] = False\n",
        "        mask = torch.tensor(black ^ white, dtype=torch.float32).to(DEVICE)\n",
        "\n",
        "        return mask\n",
        "\n",
        "    def channel_split_mask(self, in_channels, size):\n",
        "        mask = torch.zeros([1, in_channels, size[0], size[1]], dtype=torch.float32).to(DEVICE)\n",
        "        channels_i = np.arange(0, in_channels // 4) * 4\n",
        "        channels_i = np.stack((channels_i, channels_i + 1), axis=1).reshape(-1)\n",
        "        mask[:, channels_i, :, :] = 1.0\n",
        "\n",
        "        return mask\n",
        "    \n",
        "    def squeeze(self, x):\n",
        "        b, c, h, w = x.shape\n",
        "        return F.unfold(x, (2, 2), stride=2).reshape(b, 4 * c, h // 2, w // 2)\n",
        "\n",
        "    def unsqueeze(self, x):\n",
        "        b, c, h, w = x.shape\n",
        "        return F.fold(x.reshape(b, c, -1), (h * 2, w * 2), (2, 2), stride=2)\n",
        "            \n",
        "    def forward(self, x):\n",
        "        # logdet = torch.zeros(x.shape[0]).to(DEVICE)\n",
        "        # y = x\n",
        "        logdet = self.preprocess(x)\n",
        "        y = self.preprocess.latent(x)\n",
        "        # print(torch.sum(torch.isnan(y)))\n",
        "\n",
        "        for layer in self.couplings1:\n",
        "            logdet += layer(y)\n",
        "            y = layer.latent(y)\n",
        "\n",
        "        y = self.squeeze(y)\n",
        "        \n",
        "        for layer in self.couplings2:\n",
        "            logdet += layer(y)\n",
        "            y = layer.latent(y)\n",
        "        for layer in self.couplings3:\n",
        "            logdet += layer(y)\n",
        "            y = layer.latent(y)\n",
        "\n",
        "        y = self.squeeze(y)\n",
        "        \n",
        "        for layer in self.couplings4:\n",
        "            logdet += layer(y)\n",
        "            y = layer.latent(y)\n",
        "        for layer in self.couplings5:\n",
        "            logdet += layer(y)\n",
        "            y = layer.latent(y)\n",
        "        \n",
        "        logdet = torch.exp(torch.clamp(logdet, min=-MAX_VALUE, max=MAX_VALUE))\n",
        "\n",
        "        return logdet\n",
        "        \n",
        "    def latent(self, x):\n",
        "        # y = x\n",
        "        y = self.preprocess.latent(x)\n",
        "        \n",
        "        for layer in self.couplings1:\n",
        "            y = layer.latent(y)\n",
        "\n",
        "        y = self.squeeze(y)\n",
        "        \n",
        "        for layer in self.couplings2:\n",
        "            y = layer.latent(y)\n",
        "        for layer in self.couplings3:\n",
        "            y = layer.latent(y)\n",
        "\n",
        "        y = self.squeeze(y)\n",
        "        \n",
        "        for layer in self.couplings4:\n",
        "            y = layer.latent(y)\n",
        "        for layer in self.couplings5:\n",
        "            y = layer.latent(y)\n",
        "\n",
        "        y = self.unsqueeze(y)\n",
        "        y = self.unsqueeze(y)\n",
        "        \n",
        "        return y\n",
        "\n",
        "    def inverse(self, y):\n",
        "        x = y\n",
        "        x = self.squeeze(x)\n",
        "        x = self.squeeze(x)\n",
        "        \n",
        "        for layer in reversed(self.couplings5):\n",
        "            x = layer.inverse(x)\n",
        "        for layer in reversed(self.couplings4):\n",
        "            x = layer.inverse(x)\n",
        "            \n",
        "        x = self.unsqueeze(x)\n",
        "        \n",
        "        for layer in reversed(self.couplings3):\n",
        "            x = layer.inverse(x)\n",
        "        for layer in reversed(self.couplings2):\n",
        "            x = layer.inverse(x)\n",
        "            \n",
        "        x = self.unsqueeze(x)\n",
        "        \n",
        "        for layer in reversed(self.couplings1):\n",
        "            x = layer.inverse(x)\n",
        "            \n",
        "        x = self.preprocess.latent(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def __call__(self, x):\n",
        "        return self.forward(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "b6914e66-29b3-492f-d40f-0cda97cdac05",
        "id": "qBd-rgr7d1QI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "wandb.init(entity=\"vadim-farutin\", project=\"HSE-DUL-HW02-3\")\n",
        "wandb.watch_called = False # Re-run the model without restarting the runtime, unnecessary after our next release\n",
        "\n",
        "config = wandb.config\n",
        "config.lr = 5e-4\n",
        "config.batch_size = 64\n",
        "config.epochs = 2"
      ],
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/vadim-farutin/HSE-DUL-HW02-3\" target=\"_blank\">https://app.wandb.ai/vadim-farutin/HSE-DUL-HW02-3</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/vadim-farutin/HSE-DUL-HW02-3/runs/qvsrok3d\" target=\"_blank\">https://app.wandb.ai/vadim-farutin/HSE-DUL-HW02-3/runs/qvsrok3d</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrXAopx7Kbxx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from torchsummary import summary\n",
        "# summary(model, (3, 32, 32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IJknelYMd1RS",
        "colab": {}
      },
      "source": [
        "channels, size = 3, (32, 32)\n",
        "model = MyRealNVP(channels, size).float().to(DEVICE)\n",
        "loss_function = MyNLLLoss\n",
        "optimizer = optim.Adam(model.parameters(), lr=config.lr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Y3s-B0i4d1Rb",
        "colab": {}
      },
      "source": [
        "train_loss_values, val_loss_values =\\\n",
        "    fit(model, train, val, optimizer, loss_function, config.epochs, config.batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab_type": "code",
        "id": "PyIau5eBjCa3",
        "outputId": "1654bf07-a554-4d17-e378-718edb6319e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "plot_loss_values(train_loss_values, val_loss_values)"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njHYAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNFzLWXTvXX_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}