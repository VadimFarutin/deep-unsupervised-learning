{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HSE_DUL_HW03_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VadimFarutin/deep-unsupervised-learning/blob/hw03/hw03_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJqNPVBJroKY",
        "colab_type": "text"
      },
      "source": [
        "# HW03"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SrQu_IAartq0",
        "colab_type": "text"
      },
      "source": [
        "## 2 High-dimensional data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okcxjqsMkjkB",
        "colab_type": "text"
      },
      "source": [
        "### Imports and common code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfYk_JjWsim4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!pip install graphql-core==2.0\n",
        "!pip install wandb -q"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mx6pvu3gspLN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "6201fa1e-6ade-4d79-d3a7-bab4c6e1257e"
      },
      "source": [
        "import wandb\n",
        "!wandb login"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Use an existing W&B account'\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://app.wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter: 8c292ca69e334e8a562d4a4c6570fdd3ad29c825\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[32mSuccessfully logged in to Weights & Biases!\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GdLTPv3xdKi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import defaultdict\n",
        "from tqdm import tnrange, tqdm_notebook\n",
        "from tqdm.auto import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "import random\n",
        "import pickle\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.utils as utils\n",
        "from torch.nn.modules import loss\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data.dataset import Dataset\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.distributions import Normal, Uniform, MultivariateNormal"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnFSXUV3xdK0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SEED = 42\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SScqRwFfyRlx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPS = 1e-9"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "th_KCfdCxdLC",
        "colab_type": "code",
        "outputId": "0614b76f-a58f-4759-cb85-6628b7bdbcb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# DEVICE = torch.device('cpu')\n",
        "print(DEVICE)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQAiBChL3h3q",
        "colab_type": "code",
        "outputId": "bc6c625c-18be-4ba9-c2c6-fbfaf49eb45c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNCHvBCxD7Ds",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_data():\n",
        "    path = 'drive/My Drive/hw3-q2.pkl'\n",
        "\n",
        "    with open(path, 'rb') as file:\n",
        "        dataset = pickle.load(file)\n",
        "    \n",
        "    return dataset['train'].transpose(0, 3, 1, 2), dataset['valid'].transpose(0, 3, 1, 2), dataset['test'].transpose(0, 3, 1, 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUInsF-KEE6x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c877b233-c58e-483c-90bf-0ba89306d7a4"
      },
      "source": [
        "train, val, test = read_data()\n",
        "print(train.shape, val.shape, test.shape)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(65931, 3, 32, 32) (7326, 3, 32, 32) (26032, 3, 32, 32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVme0550TOcV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def MyVAELosses(x, mu_x, var_x, mu_z, var_z):\n",
        "    nll = -torch.sum(-0.5 * (torch.log(2 * np.pi * var_x) + torch.pow(x - mu_x, 2) / var_x), dim=1, keepdim=True)\n",
        "    kl_div = -0.5 * torch.sum(1.0 + torch.log(var_z) - torch.pow(mu_z, 2) - var_z, dim=1, keepdim=True)\n",
        "\n",
        "    return torch.mean(kl_div + nll), torch.mean(kl_div), torch.mean(nll) / 2.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xw73WgmxdNT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit(model, train, val, test, optimizer, loss_function, epoch_cnt, batch_size):\n",
        "    train_loader = torch.utils.data.DataLoader(torch.from_numpy(train), batch_size=batch_size, shuffle=True)\n",
        "    val_loader = torch.utils.data.DataLoader(torch.from_numpy(val), batch_size=batch_size)\n",
        "    test_loader = torch.utils.data.DataLoader(torch.from_numpy(test), batch_size=batch_size)\n",
        "    train_loss_values = []\n",
        "    val_loss_values = []\n",
        "            \n",
        "    for epoch in tnrange(epoch_cnt, desc='Epoch'):\n",
        "        model.train()\n",
        "        for batch_data in train_loader:\n",
        "            x = batch_data.float().to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            mu_x, var_x, mu_z, var_z = model(x)\n",
        "            loss, kl_div, nll = loss_function(x, mu_x, var_x, mu_z, var_z)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss_values.append([loss.item(), kl_div.item(), nll.item()])\n",
        "\n",
        "        loss_values = []\n",
        "        model.eval()\n",
        "        for batch_data in val_loader:\n",
        "            x = batch_data.float().to(DEVICE)\n",
        "            mu_x, var_x, mu_z, var_z = model(x)\n",
        "            loss, kl_div, nll = loss_function(x, mu_x, var_x, mu_z, var_z)\n",
        "            loss_values.append([loss.item(), kl_div.item(), nll.item()])\n",
        "        val_loss_values.append(np.mean(np.array(loss_values), axis=0))\n",
        "    \n",
        "    loss_values = []\n",
        "    model.eval()\n",
        "    for batch_data in test_loader:\n",
        "        x = batch_data.float().to(DEVICE)\n",
        "        mu_x, var_x, mu_z, var_z = model(x)\n",
        "        loss, kl_div, nll = loss_function(x, mu_x, var_x, mu_z, var_z)\n",
        "        loss_values.append([loss.item(), kl_div.item(), nll.item()])\n",
        "\n",
        "    print(\"Test set loss: \", np.mean(np.array(loss_values), axis=0))\n",
        "\n",
        "    return np.array(train_loss_values), np.array(val_loss_values) \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsH8OQi0xdNy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_loss_values(train_loss_values, val_loss_values, ax, title):\n",
        "    ax.plot(np.arange(len(train_loss_values)), train_loss_values, color='blue', label='train')\n",
        "    ax.plot(np.arange(0, len(train_loss_values), len(train_loss_values) / epochs), val_loss_values, color='red', label='validation')\n",
        "    ax.legend()\n",
        "    ax.set_title(title)\n",
        "    ax.set_xlabel(\"iteration\")\n",
        "    ax.set_ylabel(title)\n",
        "\n",
        "def plot_samples(decoder, n, ax):\n",
        "    z = torch.randn([n, 2]).to(DEVICE)\n",
        "    mu_x, var_x = decoder(z)\n",
        "    x = mu_x + torch.randn([n, 2]).to(DEVICE) * torch.sqrt(var_x)\n",
        "\n",
        "    x = x.cpu().data.numpy()\n",
        "    mu_x = mu_x.cpu().data.numpy()\n",
        "    \n",
        "    ax.scatter(x[:, 0], x[:, 1], marker='.', label='Full generation path')\n",
        "    ax.scatter(mu_x[:, 0], mu_x[:, 1], marker='.', label='Without decoder noise')\n",
        "\n",
        "def plot_losses_and_samples(train_loss_values, val_loss_values, decoder, n):\n",
        "    fig = plt.figure(figsize=(7, 7))\n",
        "    gs = gridspec.GridSpec(2, 2)\n",
        "\n",
        "    plot_loss_values(train_loss_values[:, 0], val_loss_values[:, 0], plt.subplot(gs[0]), \"Loss\")\n",
        "    plot_loss_values(train_loss_values[:, 1], val_loss_values[:, 1], plt.subplot(gs[1]), \"KL\")\n",
        "    plot_loss_values(train_loss_values[:, 2], val_loss_values[:, 2], plt.subplot(gs[2]), \"Decoder\")\n",
        "    plot_samples(decoder, n, plt.subplot(gs[3]))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UL4E0TEoxh3b",
        "colab_type": "text"
      },
      "source": [
        "## 2.1 Part A"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTk_y8BeNb1H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GatedShortcutConnection(nn.Module):\n",
        "    def __init__(self, hidden_size):\n",
        "        super(GatedShortcutConnection, self).__init__()\n",
        "                 \n",
        "        self.conv1 = nn.Conv2d(hidden_size, hidden_size, kernel_size=1)\n",
        "        self.conv2 = nn.Conv2d(hidden_size, hidden_size, kernel_size=1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "                 \n",
        "    def forward(self, x):\n",
        "        return self.conv1(x) * self.sigmoid(self.conv2(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "830Ia--ERUDI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_size):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "\n",
        "        self.layers = nn.Sequential(nn.ReLU(),\n",
        "                                    nn.Conv2d(in_channels, hidden_size, kernel_size=3, padding=1),\n",
        "                                    nn.ReLU(),\n",
        "                                    nn.Conv2d(hidden_size, hidden_size * 2, kernel_size=3, padding=1),\n",
        "                                    GatedShortcutConnection(hidden_size * 2))\n",
        "                 \n",
        "    def forward(self, x):\n",
        "        return self.layers(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziIZy-MDNi9k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResidualStack(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_size):\n",
        "        super(ResidualStack, self).__init__()\n",
        "\n",
        "        self.layers = nn.Sequential(ResidualBlock(in_channels, hidden_size),\n",
        "                                    ResidualBlock(hidden_size * 2, hidden_size),\n",
        "                                    ResidualBlock(hidden_size * 2, hidden_size),\n",
        "                                    ResidualBlock(hidden_size * 2, hidden_size),\n",
        "                                    ResidualBlock(hidden_size * 2, hidden_size),\n",
        "                                    nn.ReLU())\n",
        "                 \n",
        "    def forward(self, x):\n",
        "        return self.layers(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHosu3By5hJv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_size):\n",
        "        super(Encoder, self).__init__()\n",
        "        \n",
        "        self.hidden_size = hidden_size\n",
        "        \n",
        "        self.layers = nn.Sequential(nn.Conv2d(in_channels, hidden_size, kernel_size=4, stride=2, padding=1),\n",
        "                                    nn.ReLU(),\n",
        "                                    nn.Conv2d(hidden_size, hidden_size * 2, kernel_size=4, stride=2, padding=1),\n",
        "                                    nn.ReLU(),\n",
        "                                    nn.Conv2d(hidden_size * 2, hidden_size * 4, kernel_size=3, padding=1),\n",
        "                                    nn.ReLU(),\n",
        "                                    ResidualStack(hidden_size * 4, hidden_size))\n",
        "                 \n",
        "    def forward(self, x):\n",
        "        out = self.layers(x)\n",
        "        out = out.reshape(-1, 2, 2 * self.hidden_size, 8, 8)\n",
        "        mu, log_var = out[:, 0], out[:, 1]\n",
        "\n",
        "        return mu, torch.exp(log_var)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5_43rXkNJDL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_size, out_channels):\n",
        "        super(Decoder, self).__init__()\n",
        "        \n",
        "        self.out_channels = out_channels\n",
        "        \n",
        "        self.layers = nn.Sequential(nn.Conv2d(in_channels, hidden_size * 4, kernel_size=3, padding=1),\n",
        "                                    ResidualStack(hidden_size * 4, hidden_size),\n",
        "                                    nn.ConvTranspose2d(hidden_size * 2, hidden_size * 2, kernel_size=4, stride=2, padding=1),\n",
        "                                    nn.ReLU(),\n",
        "                                    nn.ConvTranspose2d(hidden_size * 2, out_channels * 2, kernel_size=4, stride=2, padding=1))\n",
        "                 \n",
        "    def forward(self, x):\n",
        "        out = self.layers(x)\n",
        "        out = out.reshape(-1, 2, self.out_channels, 32, 32)\n",
        "        mu, log_var = out[:, 0], out[:, 1]\n",
        "\n",
        "        return mu, torch.exp(log_var)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHKZ9wnVNgnj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class VAE(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super(VAE, self).__init__()\n",
        "       \n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, x):\n",
        "        mu_z, var_z = self.encoder(x)\n",
        "        z = mu_z + torch.randn(x.shape).to(DEVICE) * torch.sqrt(var_z)\n",
        "        mu_x, var_x = self.decoder(z)\n",
        "\n",
        "        return mu_x, var_x, mu_z, var_z"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cm486oUxgGE0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "in_channels = 3\n",
        "out_channels = 3\n",
        "hidden_size = 128\n",
        "lr = 1e-3\n",
        "batch_size = 128\n",
        "epochs = 10\n",
        "n_samples = 10000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtb86hOf_R6H",
        "colab_type": "code",
        "outputId": "05520577-23c9-414a-a72e-27648965acf8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85,
          "referenced_widgets": [
            "71f0fae5ed5d4c618a0ebadac9d89747",
            "7681dd60ba144f44820f2d4285b1669f",
            "991015d6983545d28d23957ec093b89b",
            "1fb037ea6f0645fd92379beb95d9a538",
            "9942b711e48241dda597b0711648e5c7",
            "794bbcea8ebd49df83fe2dc240ff9a6d",
            "57c05c25ccab416b8a41963cc1e1b48a",
            "bc2777d8c67b4dd09fcc86a1ee21e7aa"
          ]
        }
      },
      "source": [
        "encoder = Encoder(in_channels=in_channels, hidden_size=hidden_size)\n",
        "decoder = Decoder(in_channels=in_channels, hidden_size=hidden_size, out_channels=out_channels)\n",
        "model = VAE(encoder, decoder).float().to(DEVICE)\n",
        "\n",
        "loss_function = MyVAELosses\n",
        "optimizer = optim.Adam(encoder.parameters(), lr=lr)\n",
        "\n",
        "train_loss_values, val_loss_values =\\\n",
        "    fit(model, train, val, test, optimizer, loss_function, epochs, batch_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "71f0fae5ed5d4c618a0ebadac9d89747",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Epoch', max=10, style=ProgressStyle(description_width='initia…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set loss:  [4.44404249e+00 1.54236319e-03 2.22125006e+00]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnkWGAYEDP-c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_losses_and_samples(train_loss_values, val_loss_values, decoder, n_samples)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LrKi8YZ4wqjH",
        "colab_type": "text"
      },
      "source": [
        "## 2.2 Part B"
      ]
    }
  ]
}